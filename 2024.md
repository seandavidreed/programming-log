# Year: 2024

---
### Table of Contents
[January](#112023)  

### Resources
["The end of the 'Self-Taught Programmer'"](https://youtu.be/ro4oGwMb-T4?si=5SgKq55R36pFydau) [*1/1/2024*](#112024)   


---
### 1/1/2024
#### GOALS
What are my main goals for this year? What follows is my attempt to answer that:  
1. Get a new job.
    * My good friend's dad got me in contact with a guy who needs a Python developer. We had a meetup a couple of weeks ago, and I reached out to him by email afterward to confirm I am interested in joining the project. I've yet to hear back, but I'm optimistic that this could become my first legitimate development job! It would be part-time, so I'd have to continue with my current job alongside it.
2. Pursue a Masters Degree from CU Boulder
    * Since the opportunity mentioned above came my way, I'm thinking this goal needs to be pushed to springtime or later. I'm still preparing for it by taking preliminary classes on Coursera, but I don't want to try to start the degree program this January while also starting the part-time job! Nevertheless, this goal still remains a priority!
3. Hone my interests / Build something robust
    * These two goals go hand in hand. I don't want to start any old project but something that will further my goals. I watched a video that inspired me to explore frontend frameworks like *React*. [This video](https://youtu.be/ro4oGwMb-T4?si=5SgKq55R36pFydau), "The end of the 'Self-Taught Programmer'," outlines important skills to learn if one wants to tand up an application from end-to-end while developing on demand skills. He bases his recommendations on the desired qualifications written in a job posting. Here they are:
      * React development, Javascript, Redux, RESTful APIs, authorization mechanisms, continuous integration and delivery technologies, agile scrum development methodology.
    * I'm still interested in Artificial Intelligence and Deep Learning - I'd really like to continue with the fastai program, but I think it needs to be on hold for the moment while I see how the potential job opportunity pans out.
    * I really want to get back into writing stuff in the C language again, and that probably entails embedded systems, IoT, etc. If I explore that route, I want to do it right, with laser focus. I want to start on a project straight away and use it as a platform to become familiar with all the skills and technologies I need.
    * I'd like to get a more intuitive understanding of how the internet works. This is partly what makes me interested in IoT since it marries two arenas I'm interested in: embedded systems and the internet in general. 
    * Finally, my main focus is to get more proficient in the most marketable skills, and that probably means Python. I already am comfortable writing in Python, but I'd like to take my skills to the next level. Hopefuly this part-time job opportunity will be the vehicle for that goal!

### 1/2/2024
#### CU Boulder Algorithms Module 1
>Exercise 3.1-1  
>Let $f(n)$ and $g(n)$ be asymptotically nonnegative functions. Using the basic  definition of $\Theta$-notation, prove that max($f(n)$, $g(n)$) $= \Theta(f(n) + g(n))$.

$\text{let } \text{max}(f(n), g(n)) = f(n), \text{ and } f(n) = n^2,\, g(n) = n,\\ 
\text{so } \Theta(f(n) + g(n)) = \Theta(n^2 + n)$

When asymptotically evaluating a function such as $n^2 + n$, we only care about the highest-order term since it will dominate the growth of the function as $n$ increases.

$\text{therefore } \Theta(f(n) + g(n)) = \Theta(n^2 + n) = \Theta(n^2) = \Theta(f(n))\\
\text{and we know } f(n) = \Theta(f(n)),\\
\text{so } f(n) = \Theta(f(n) + g(n))$.

>Exercise 3.1-2  
>Show that for any real constants $a$ and $b$, where $b > 0$, $(n + a)^b = \Theta(n^b)$.

Let's expand $(n + a)^b$, let $c_i$ for all values of $i$ be some constant we don't care about:

$n^b + c_{b-1}n^{b-1}a^1 + c_{b-2}n^{b-2}a^2 + ... + c_2n^2a^{b-2} + c_1n^1a^{b-1} + a^b$

Since $a$ and $b$ are constants and we are generally not concerned about constants in asymptotic analysis, let's "absorb" $a$ and $b$ into $c$ where possible:

$n^b + c_{b-1}n^{b-1} + c_{b-2}n^{b-2} + ... + c_2n^2 + c_1n$

Let's remove the constants entirely now:

$n^b + n^{b-1} + n^{b-2} + ... + n^2 + n$

Here we see that the first term is the highest-order term since $b$ must be greater than itself minus any positive number. We know that the highest-order term will dominate the growth of the function, and that is the term we care about. We can remove all terms of lower orders than $n^b$. Therefore,

$(n + a)^b = \Theta(n^b)$.

>Exercise 3.1-3  
>Explain why the statement, "The running time of algorithm $A$ is at least $O(n^2)$," is meaningless.

Big-O notation describes an *asymptotically-tight* **upper bound** of a given function. As such, it describes the highest possible (worst-case) running time of the function. Therefore, the above statement says "The running time of algorithm $A$ is at least its highest possible running time, which is a redundant way of saying $A$ has exactly one running time. It would be correct to say that the running time of algorithm $A$ is *at most* $O(n^2)$.

>Exercise 3.1-4  
>Is $2^{n+1} = O(2^n)$? Is $2^{2n} = O(2^n)$?

To the first question, the answer is yes. We can provide a constant $K$:


$\text{let } f(n) = 2^{n+1}\\
\text{let } g(n) = 2^{n}\\
f(n) = O(Kg(n)) \iff K \geq 2$

When $K \geq 2$, $g(n) \geq f(n)$ for all $N_0 > 0$.

To the second question, the answer is no. No matter what constant $K$ we provide for $g(n)$, $f(n)$ will always eventually overtake $g(n)$ for all sufficiently large $n$, which means $g(n)$ is not an upper bound of $f(n)$.

>Exercise 3.1-5 
>Prove Theorem 3.1.

First, I'll state the theorem:

For any two functions $f(n)$ and $g(n)$, we have $f(n) = \Theta(g(n))$ if and only if $f(n) = O(g(n))$ and $f(n) = \Omega(g(n))$.

By definition, $f(n) = \Theta(g(n))$ means that $0 \leq c_1g(n) \leq f(n) \leq c_2g(n),\, \forall n > N_0 \text{ and } \forall c_1: c_1 \geq 0, \text{ and } \forall c_2: c_2 \geq 0$.

By definition, $f(n) = O(g(n))$ means that $0 \leq f(n) \leq cg(n),\, \forall n \geq N_0 \text{ and } \forall c: c \geq 0$.

By definition, $f(n) = \Omega(g(n))$ means that $0 \leq cg(n) \leq f(n),\, \forall n \geq N_0 \text{ and } \forall c:c \geq 0$.

We see that $\Theta$ is merely the combination of $O$ and $\Omega$. Therefore, if both $f(n) = O(g(n))$ and $f(n) = \Omega(g(n))$ hold, then $f(n) = \Theta(g(n))$ also holds.

>Exercise 3.1-7
>Prove that $o(g(n)) \cap \omega(g(n))$ is the empty set.

$o(g(n))$ is $g(n)$ as an upper bound (not *asymptotically tight*) to some other function (suppose $f(n)$) or set of functions. That is, $0 \leq f(n) < g(n)$. 

$\omega(g(n))$ is $g(n)$ as a lower bound (not *asymptotically tight*) to some other function or set of functions. That is $0 \leq g(n) < f(n)$.

Notice that in $f(n) = o(g(n))$, $f(n) \neq g(n)$. Additionally, in $f(n) = \omega(g(n))$, $f(n) \neq g(n)$. Therefore, $o(g(n)) \cap \omega(g(n)) = \emptyset$.

>Exercise 3.1-8
>We can extend our notation to the case of two parameters $n$ and $m$ that can go to infinity independently at different rates. For a given function $g(n,m)$, we denote by $O(g(n,m)) the set of functions

>$O(g(n,m)) = {f(n,m): \exists(c, n_0, m_0): 0 \leq f(n,m) \leq cg(n,m)\ \forall n \geq n_0 \text{ or } m \geq m_0}$

$\Omega(g(n,m)) = {f(n,m): \exists(c, n_0, m_0): 0 \leq cg(n,m) \leq f(n,m)\ \forall n \geq n_0 \text{ or } m \geq m_0}$.

$\Theta(g(n,m)) = {f(n,m): \exists(c_1, c_2, n_0, m_0): 0 \leq c_1g(n,m) \leq f(n,m) \leq c_2g(n,m)\ \forall n \geq n_0 \text{ or } m \geq m_0}$.